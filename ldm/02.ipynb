{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert in utils \n",
    "def accuracy_fn(pred, y):\n",
    "    return (pred.argmax(dim=1) == y).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert in utils \n",
    "\n",
    "def report(loss, pred, y):\n",
    "    print(f'{loss:.2f}, {accuracy_fn(preds, yb):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, default_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(train_dataset, test_dataset, batch_size):\n",
    "    return (\n",
    "        DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=default_collate), \n",
    "        DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, collate_fn=default_collate),\n",
    "        train_dataset.classes\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_dataloader, test_dataloader, class_names = dataloader(train_dataset, test_dataset, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conv import *\n",
    "cnn = nn.Sequential(\n",
    "    conv(1, 4),\n",
    "    conv(4, 8),\n",
    "    conv(8, 16),\n",
    "    conv(16, 16),\n",
    "    conv(16, 10, act=False),\n",
    "    nn.Flatten()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.4\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=cnn.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert in train \n",
    "\n",
    "def fit(epochs, model, train_dataloader, test_dataloader, loss_fn, optimizer, device):\n",
    "    for epoch in range(epochs):\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "        for X, y in train_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            loss = loss_fn(model(X), y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            tot_loss, tot_acc, count = 0.,0.,0\n",
    "            for X, y in test_dataloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                pred = model(X)\n",
    "                n = len(X)\n",
    "                count += n\n",
    "                tot_loss += loss_fn(pred, y).item()*n\n",
    "                tot_acc += accuracy_fn(pred, y).item()*n\n",
    "        print(\"--------------------\")\n",
    "        print(count)\n",
    "        print(tot_loss)\n",
    "        print(tot_acc)\n",
    "        print(\"--------------------\")\n",
    "        print(epoch, tot_loss/count, tot_acc/count)\n",
    "        print(\"--------------------\")\n",
    "    return tot_loss/count, tot_acc/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "10000\n",
      "5402.981855869293\n",
      "7994.0\n",
      "--------------------\n",
      "0 0.5402981855869293 0.7994\n",
      "--------------------\n",
      "--------------------\n",
      "10000\n",
      "4829.3821268081665\n",
      "8239.0\n",
      "--------------------\n",
      "1 0.48293821268081666 0.8239\n",
      "--------------------\n",
      "--------------------\n",
      "10000\n",
      "5477.206356525421\n",
      "7935.0\n",
      "--------------------\n",
      "2 0.5477206356525421 0.7935\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5477206356525421, 0.7935)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(epochs=3, model=cnn, loss_fn=loss_fn, optimizer=optimizer, train_dataloader=train_dataloader, test_dataloader=test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(pred, y):\n",
    "    return (pred.argmax(dim=1) == y).sum().item() / len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def fit_2(epochs, model, train_dataloader, test_dataloader, loss_fn, optimizer, device):\n",
    "    model.to(device)\n",
    "    \n",
    "    train_count, test_count = 0, 0\n",
    "    train_loss, train_acc, test_loss, test_acc = 0, 0, 0, 0\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        for X, y in train_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y) \n",
    "            train_loss += loss\n",
    "            train_acc += accuracy_fn(y_pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for X, y in test_dataloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                test_pred = model(X)\n",
    "                test_loss += loss_fn(test_pred, y)\n",
    "                test_acc += accuracy_fn(pred=test_pred, y=y)\n",
    "        \n",
    "        train_count = len(train_dataloader)*(epoch+1)\n",
    "        test_count = len(test_dataloader)*(epoch+1)\n",
    "        \n",
    "        print(f\"| Epoch: {epoch} | Train loss: {train_loss / train_count } | Train accuracy: {train_acc / train_count} | Test loss: {test_loss / test_count} | Test accuracy: {test_acc / test_count} |\")\n",
    "    return (\n",
    "        train_loss.item() / train_count,\n",
    "        train_acc / train_count,\n",
    "        test_loss.item() / test_count,\n",
    "        test_acc / test_count\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:07<00:14,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 0 | Train loss: 0.43925905227661133 | Train accuracy: 0.8366371268656716 | Test loss: 0.4506646394729614 | Test accuracy: 0.8305135350318471 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:14<00:07,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 1 | Train loss: 0.42257019877433777 | Train accuracy: 0.8426255996801706 | Test loss: 0.4428204596042633 | Test accuracy: 0.834593949044586 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:21<00:00,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 2 | Train loss: 0.4139711856842041 | Train accuracy: 0.8455545931058991 | Test loss: 0.4388471245765686 | Test accuracy: 0.8383094479830149 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.41397118585365583,\n",
       " 0.8455545931058991,\n",
       " 0.43884711457918657,\n",
       " 0.8383094479830149)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_2(epochs=3, model=cnn, loss_fn=loss_fn, optimizer=optimizer, train_dataloader=train_dataloader, test_dataloader=test_dataloader, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
