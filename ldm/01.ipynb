{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert in utils \n",
    "def accuracy_fn(pred, y):\n",
    "    return (pred.argmax(dim=1) == y).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert in utils \n",
    "\n",
    "def report(loss, pred, y):\n",
    "    print(f'{loss:.2f}, {accuracy_fn(preds, yb):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dataloader\n",
    "BATCH_SIZE = 64\n",
    "train_dataloader, test_dataloader, class_names = dataloader(train_dataset, test_dataset, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conv import *\n",
    "cnn = nn.Sequential(\n",
    "    conv(1, 4),\n",
    "    conv(4, 8),\n",
    "    conv(8, 16),\n",
    "    conv(16, 16),\n",
    "    conv(16, 10, act=False),\n",
    "    nn.Flatten()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.4\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=cnn.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert in train \n",
    "\n",
    "def fit(epochs, model, train_dataloader, test_dataloader, loss_fn, optimizer, device):\n",
    "    for epoch in range(epochs):\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "        for X, y in train_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            loss = loss_fn(model(X), y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            tot_loss, tot_acc, count = 0.,0.,0\n",
    "            for X, y in test_dataloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                pred = model(X)\n",
    "                n = len(X)\n",
    "                count += n\n",
    "                tot_loss += loss_fn(pred, y).item()*n\n",
    "                tot_acc += accuracy_fn(pred, y).item()*n\n",
    "        print(\"--------------------\")\n",
    "        print(count)\n",
    "        print(tot_loss)\n",
    "        print(tot_acc)\n",
    "        print(\"--------------------\")\n",
    "        print(epoch, tot_loss/count, tot_acc/count)\n",
    "        print(\"--------------------\")\n",
    "    return tot_loss/count, tot_acc/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "10000\n",
      "4014.6596205234528\n",
      "8445.0\n",
      "--------------------\n",
      "0 0.40146596205234525 0.8445\n",
      "--------------------\n",
      "--------------------\n",
      "10000\n",
      "4451.583886146545\n",
      "8364.0\n",
      "--------------------\n",
      "1 0.44515838861465457 0.8364\n",
      "--------------------\n",
      "--------------------\n",
      "10000\n",
      "4410.060415506363\n",
      "8392.0\n",
      "--------------------\n",
      "2 0.4410060415506363 0.8392\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4410060415506363, 0.8392)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(epochs=3, model=cnn, loss_fn=loss_fn, optimizer=optimizer, train_dataloader=train_dataloader, test_dataloader=test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def fit_2(epochs, model, train_dataloader, test_dataloader, loss_fn, optimizer, device):\n",
    "    model.to(device)\n",
    "    \n",
    "    train_count, test_count = 0, 0\n",
    "    train_loss, train_acc, test_loss, test_acc = 0, 0, 0, 0\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        for X, y in train_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y) \n",
    "            train_loss += loss\n",
    "            train_acc += accuracy_fn(y_pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for X, y in test_dataloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                test_pred = model(X)\n",
    "                test_loss += loss_fn(test_pred, y)\n",
    "                test_acc += accuracy_fn(pred=test_pred, y=y)\n",
    "        \n",
    "        train_count = len(train_dataloader)*(epoch+1)\n",
    "        test_count = len(test_dataloader)*(epoch+1)\n",
    "        \n",
    "        print(f\"| Epoch: {epoch} | Train loss: {train_loss / train_count } | Train accuracy: {train_acc / train_count} | Test loss: {test_loss / test_count} | Test accuracy: {test_acc / test_count} |\")\n",
    "    return (\n",
    "        train_loss.item() / train_count,\n",
    "        train_acc / train_count,\n",
    "        test_loss.item() / test_count,\n",
    "        test_acc / test_count\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:06<00:13,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 0 | Train loss: 0.34500396251678467 | Train accuracy: 0.8720682263374329 | Test loss: 0.49899420142173767 | Test accuracy: 0.8213574886322021 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:13<00:06,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 1 | Train loss: 0.34374773502349854 | Train accuracy: 0.8717517256736755 | Test loss: 0.4580437242984772 | Test accuracy: 0.8358380198478699 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:20<00:00,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 2 | Train loss: 0.3419395089149475 | Train accuracy: 0.8724180459976196 | Test loss: 0.4411463737487793 | Test accuracy: 0.8426221013069153 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.34193950726279315,\n",
       " tensor(0.8724, device='cuda:0'),\n",
       " 0.4411463646372412,\n",
       " tensor(0.8426, device='cuda:0'))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_2(epochs=3, model=cnn, loss_fn=loss_fn, optimizer=optimizer, train_dataloader=train_dataloader, test_dataloader=test_dataloader, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
