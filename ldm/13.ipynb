{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils import *\n",
    "from learner import *\n",
    "from unet import *\n",
    "from attention import *\n",
    "from time_embedding import *\n",
    "from vae import *\n",
    "from ddpm import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((32, 32))])\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collate(batch):\n",
    "    X, y = zip(*batch)\n",
    "    ddpm = DDPM(0, 1, 5)\n",
    "    X = torch.stack(X, dim=0)\n",
    "    y = torch.tensor(y)\n",
    "    (X, t), noise = ddpm.schedule(X)\n",
    "    return (X, t, y), noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(train_dataset, test_dataset, batch_size, collate_fn=None):\n",
    "    return (\n",
    "        DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn), \n",
    "        DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    )\n",
    "train_dataloader, test_dataloader = dataloader(train_dataset, test_dataset, BATCH_SIZE, data_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNET(10, 1, 1, (32,64,128,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "epochs = 25\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(unet.parameters(), lr=lr)\n",
    "schedular = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, total_steps=epochs*len(train_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs=1):\n",
    "    model.to(device)\n",
    "    for epoch in trange(epochs):\n",
    "        model.train()\n",
    "        loss_calc = 0\n",
    "        for batch, (image, noise) in enumerate(train_dataloader):\n",
    "            X, t, c = image\n",
    "            X, t, c = X.to(device), t.to(device), c.to(device)\n",
    "            image = X, t, c\n",
    "            noise = noise.to(device)\n",
    "            pred = model(image)\n",
    "            loss = loss_fn(pred, noise)\n",
    "            loss_calc += loss.item()\n",
    "            # print(f\"Batch: {loss_calc}\")\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch: {epoch} = Loss: {loss_calc/len(train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [21:54<00:00, 1314.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 = Loss: 0.22196614021658898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(unet.state_dict(), \"./Saved Models/unet_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
